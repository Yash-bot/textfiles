{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mHLAKTF1In2",
        "outputId": "78304f73-4df8-479a-9d51-f45846095b9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "19Fcdiu_1RFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooTI4zxZ1WeN",
        "outputId": "69c9b925-0d39-4674-bd89-c3384129d639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "text=\"Natural language processing (NLP) is a subfield of linguistics, \\\n",
        "      computer science, information engineering, and artificial intelligence concerned\\\n",
        "      with the interactions between computers and human language,\\\n",
        "       in particular how to program computers to process and\\\n",
        "         analyze large amounts of natural language data.\"\n",
        "print(sent_tokenize(text))\n",
        "print(word_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK9978qq1dMN",
        "outputId": "3046db65-e95f-41cf-80bf-3866b2d3d2aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural language processing (NLP) is a subfield of linguistics,       computer science, information engineering, and artificial intelligence concerned      with the interactions between computers and human language,       in particular how to program computers to process and         analyze large amounts of natural language data.']\n",
            "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize=nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "print(sent_tokenize.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF47BN6g2Biz",
        "outputId": "86ee5482-fc8d-4aa4-fd3d-4f25844d0457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural language processing (NLP) is a subfield of linguistics,       computer science, information engineering, and artificial intelligence concerned      with the interactions between computers and human language,       in particular how to program computers to process and         analyze large amounts of natural language data.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.data\n",
        "spanish_tokenizer=nltk.data.load('tokenizers/punkt/spanish.pickle')\n",
        "texts='Hola amigo,Estoy bien'\n",
        "print(spanish_tokenizer.tokenize(texts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_5zulo82qbB",
        "outputId": "1f68b6b4-c968-413d-cdd0-d2f2389657e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hola amigo,Estoy bien']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer=WordPunctTokenizer()\n",
        "print(tokenizer.tokenize(\"Let's see how its's working.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2-3a3sz4LHm",
        "outputId": "7e911615-76ec-4729-8b5e-b10cd0217572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Let', \"'\", 's', 'see', 'how', 'its', \"'\", 's', 'working', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer=RegexpTokenizer(r'\\w+')\n",
        "print(tokenizer.tokenize(\"Let's see how its's working.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmDsCXRh9N_3",
        "outputId": "2cda7cf4-8eaf-4fed-d95d-50bbdfee311d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Let', 's', 'see', 'how', 'its', 's', 'working']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer=RegexpTokenizer(r'\\s+')\n",
        "print(tokenizer.tokenize(\"Let's           see how its's working.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9LyqZOR4kG6",
        "outputId": "bb96228b-28d9-4f30-9560-0de535cd8243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['           ', ' ', ' ', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer=RegexpTokenizer(r'\\d+')\n",
        "print(tokenizer.tokenize(\"Phone Number is  241567889\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ysifh4R4xYA",
        "outputId": "892e523d-b778-4201-df86-38650274715e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['241567889']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC7Fls1Q9Icd",
        "outputId": "a1c10931-1e5f-46c1-b61b-3f31f27883cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "ueAZFDjY9noM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mystring=\"we\\'re moving to palghar. !\""
      ],
      "metadata": {
        "id": "TrQd4wvB9-cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mystring"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OapWDrvI-XdF",
        "outputId": "d21f2dfd-f78f-4d9e-d2e0-577b9e3aa22f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"we're moving to palghar. !\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(mystring) #converted"
      ],
      "metadata": {
        "id": "QdflC0X3-aMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0C0q_J9-mX8",
        "outputId": "2ad51ccf-dbde-49ef-bcd1-b2fe5d5477be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we\n",
            "'re\n",
            "moving\n",
            "to\n",
            "palghar\n",
            ".\n",
            "!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2=nlp(u\"we r available in websiite https://www.google.com and support support@gmail.com\")"
      ],
      "metadata": {
        "id": "RZ7xKbNE_Jdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc2:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4uLb19K_sg0",
        "outputId": "94f02224-8c7a-45a2-d4df-7a3cc9fa615c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we\n",
            "r\n",
            "available\n",
            "in\n",
            "websiite\n",
            "https://www.google.com\n",
            "and\n",
            "support\n",
            "support@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc3=nlp(u\"The ride coasted me Rs.54.50\")\n",
        "for token in doc3:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82yRu6te_3xT",
        "outputId": "a8e20a44-a162-4d1c-d5b9-96d70154b00b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The\n",
            "ride\n",
            "coasted\n",
            "me\n",
            "Rs.54.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc3[1].similarity(doc3[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2oTUDM-AaWz",
        "outputId": "03a214e6-2cdd-4487-f8f3-17ebc5b7411e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-f39ca99097a2>:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  doc3[1].similarity(doc3[2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03339221701025963"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc3[1].vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImvG-AFEAzNq",
        "outputId": "33962a69-9b5c-4f43-cb12-d6d4e801c313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.6058672 , -0.71769273, -0.14641446,  0.24256685,  0.05139396,\n",
              "        1.0176266 ,  2.2271316 ,  1.289621  ,  0.18049009, -0.870521  ,\n",
              "        0.33729452,  0.26462728, -0.3468396 , -1.0057542 ,  0.23750383,\n",
              "       -0.05577788,  0.14190707, -1.0036607 ,  0.2777567 , -0.10964625,\n",
              "        0.8035998 , -0.46890816,  0.10518783, -0.45922315, -0.6352043 ,\n",
              "       -0.2235036 ,  0.31840342, -0.3452401 ,  1.4646586 , -0.19911316,\n",
              "        0.03509298, -1.0554695 , -0.40834713, -0.85418   , -0.11591342,\n",
              "       -0.39952797, -0.12482367, -0.58560956,  0.97908235,  0.3951715 ,\n",
              "       -1.5039048 ,  0.7638945 ,  0.40190262,  1.0035146 ,  0.34444657,\n",
              "        0.3758559 ,  0.7069103 ,  2.4969504 ,  0.17262563, -0.15802604,\n",
              "        0.1954189 , -1.047843  , -0.24391663, -0.5835934 ,  0.9851974 ,\n",
              "       -0.6401075 ,  0.8537234 , -0.362324  , -0.73970973, -0.31930375,\n",
              "        0.25937146,  0.04177791, -1.1332467 ,  0.37985176,  1.1614695 ,\n",
              "       -0.95097446, -0.3266162 , -0.15980825,  0.74791765, -1.2896423 ,\n",
              "        0.29966605, -0.04878205,  1.4656022 , -0.4928968 , -0.24415427,\n",
              "        0.03556241,  0.20274705, -1.6504059 ,  0.20500101, -0.62200683,\n",
              "       -0.9438397 ,  0.6435789 , -1.5040376 , -0.32556432, -0.27290252,\n",
              "        0.495944  ,  0.742616  , -0.86424124, -0.8869902 , -0.34674162,\n",
              "        0.00732912, -0.19405113,  1.7089245 ,  0.5708854 , -0.1984479 ,\n",
              "        0.32642522], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a='king'\n",
        "k=nlp(a)\n",
        "k.vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KOkK5wnA79R",
        "outputId": "cd4d16f5-9e40-46ca-e709-47c862b5e110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.8038062 , -0.57184035, -1.0615969 ,  0.1685325 , -0.73480105,\n",
              "       -0.07565041,  2.47716   ,  0.34800076, -0.14537281,  0.05508129,\n",
              "        0.9790832 , -1.0621793 , -0.90454197,  0.63134384, -0.16790569,\n",
              "        0.12966211, -0.7590473 , -1.0194731 ,  1.8497288 ,  0.68561244,\n",
              "        0.42840576,  1.9528611 ,  0.71009314, -0.49444747,  0.15484339,\n",
              "        1.1637604 ,  0.32334328,  1.9428613 , -0.4038114 , -0.40275377,\n",
              "        0.03499427, -0.2542291 ,  0.72335136, -0.19704051, -0.38484254,\n",
              "       -2.0028517 , -0.04508871,  0.602212  ,  0.4824512 ,  0.08982205,\n",
              "       -0.30942625,  0.5462789 , -0.3974073 ,  0.15101105, -0.75147295,\n",
              "       -1.0158409 , -1.3755283 ,  1.5071571 ,  0.07189959,  0.38855618,\n",
              "        0.22438756,  0.430369  ,  0.81013995, -1.1247113 , -0.4688068 ,\n",
              "       -1.1177742 ,  1.0850023 ,  0.25971973,  0.28847817, -0.87373275,\n",
              "       -0.9647601 , -0.4774765 ,  0.7437953 , -0.5322264 ,  0.4202554 ,\n",
              "        0.10787368, -0.26062754,  0.47333872,  0.49753362, -2.0549963 ,\n",
              "        0.1926519 ,  0.16442215,  1.0940242 , -0.5006186 , -0.28406495,\n",
              "       -0.84961617,  0.00315695,  0.35117477,  0.46972567, -1.1229045 ,\n",
              "       -0.2193472 , -0.6019075 , -1.9369872 , -1.1479326 ,  0.06317723,\n",
              "        0.36457014,  1.0063617 , -0.06738757, -0.89169693,  1.8681461 ,\n",
              "       -1.5638493 ,  0.4468745 ,  1.8851739 ,  0.73967326,  1.1027694 ,\n",
              "        0.7580921 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a='Queen'\n",
        "w=nlp(a)\n",
        "w.vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qmAebYcBG3q",
        "outputId": "1d75c17a-f757-46bf-94ae-6efe5948af37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.4556888 , -0.23195261, -1.0676954 ,  0.48808494, -0.17063618,\n",
              "       -0.0403177 ,  0.6202977 ,  0.57027686, -0.4137466 , -0.9058193 ,\n",
              "        0.53196055, -0.14653581, -0.6895704 ,  0.3904898 , -0.5275524 ,\n",
              "        1.6309243 , -0.5934247 , -1.335506  ,  0.11048135,  0.3738405 ,\n",
              "       -1.4138916 ,  0.6705897 , -1.4824126 , -1.030883  ,  1.2003825 ,\n",
              "       -0.0562516 ,  1.0687084 ,  2.0531693 , -0.8736164 ,  0.3006286 ,\n",
              "       -0.5963938 ,  0.01758003,  1.2537479 , -0.41947055, -0.6086303 ,\n",
              "       -1.2451    ,  0.29898563,  0.9280941 ,  0.39446437,  0.6116999 ,\n",
              "        0.4315982 , -0.214507  , -0.8504759 , -0.11071873, -0.04616505,\n",
              "       -1.585584  , -0.27132463,  1.1684145 ,  0.41931903, -0.83047956,\n",
              "        0.18601042,  0.55654514, -0.514993  , -0.84665155,  1.107242  ,\n",
              "       -0.85671103,  1.9944439 , -0.5776765 , -0.04542813,  0.24333405,\n",
              "       -1.3949885 , -0.0143902 , -1.1383004 , -1.1191931 ,  1.5025545 ,\n",
              "        0.6265161 ,  0.6766325 , -0.00611244,  0.27994594, -0.39154065,\n",
              "        0.76857114,  0.84397364,  1.4656664 ,  0.08296071, -0.44316235,\n",
              "        0.35750297, -0.6178988 ,  0.05974907,  0.01154032, -0.6505361 ,\n",
              "        0.1341438 ,  0.88908184,  0.08549485, -0.383893  , -0.30176717,\n",
              "        1.2764597 ,  0.02971328, -0.26231626, -0.8242874 , -0.10319588,\n",
              "       -0.9679507 , -0.42646337,  2.552554  ,  0.43799865,  1.1384864 ,\n",
              "        1.1784391 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k.similarity(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U0QfZRlBR9-",
        "outputId": "d4632e75-8f52-4b5f-bc4b-ad2ef725f26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-11909d0da85e>:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  k.similarity(w)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44055863762835934"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a='computer'\n",
        "c=nlp(a)\n",
        "a='water'\n",
        "z=nlp(a)\n",
        "c.similarity(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRIxBVxhBseC",
        "outputId": "e5030e69-9d28-47ad-b88b-573e3871ef5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-7e2cf4fe1487>:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  c.similarity(z)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8688891083501549"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a='sea'\n",
        "c=nlp(a)\n",
        "a='river'\n",
        "z=nlp(a)\n",
        "c.similarity(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toMq_RMyCC0i",
        "outputId": "a08d6ee6-823b-4a63-d389-16a89848d6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-1c2809062b7e>:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  c.similarity(z)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6183049550882345"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc5=nlp(u\"Apple is building a  factory in India for $1M\")\n",
        "for token in doc5:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77DxS6V5CKRp",
        "outputId": "55fd6ef2-602a-4111-dd39-d939826a5319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple\n",
            "is\n",
            "building\n",
            "a\n",
            " \n",
            "factory\n",
            "in\n",
            "India\n",
            "for\n",
            "$\n",
            "1\n",
            "M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc5:\n",
        "  print(token.text,end=\"|\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D_E3x_wCo_6",
        "outputId": "9678a907-ce70-42d8-daf0-342b8dc29129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple|is|building|a| |factory|in|India|for|$|1|M|"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for entity in doc5.ents:\n",
        "  print(entity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4RNYy1rC3i6",
        "outputId": "824c2286-e3fa-42af-c878-69fad3940d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple\n",
            "India\n",
            "$1M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for entity in doc5.ents:\n",
        "  print(entity)\n",
        "  print(entity.text,entity.label_)\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcRvZOY1DA5S",
        "outputId": "a59936ac-1dcc-49b3-cd97-d0e3dc86a4bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple\n",
            "Apple ORG\n",
            "\n",
            "\n",
            "India\n",
            "India GPE\n",
            "\n",
            "\n",
            "$1M\n",
            "$1M MONEY\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qgx6FFXMDg58"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}