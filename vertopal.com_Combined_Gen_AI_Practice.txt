

Multi-Layer Perceptron

    import pandas as pd 
    import numpy as np 
    import tensorflow as tf
    import matplotlib.pyplot as plt
    import tensorflow.keras.datasets as td 
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.optimizers import Adam,RMSprop
    from tensorflow.keras.utils import to_categorical
    from tensorflow.keras.layers import Flatten,Dense,Dropout,Input
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import confusion_matrix,classification_report

    WARNING:tensorflow:From C:\Users\hp\anaconda3\Lib\site-packages\keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

    ## Use the data for multi layer such as Mnist data for classification
    (X_train,y_train),(X_test,y_test)=td.mnist.load_data()

    ## Rescale and convert the data into one hot encoding 
    X_train=X_train.astype("float32")/255.0
    X_test=X_test.astype("float32")/255.0
    y_train=to_categorical(y_train,10)
    y_test=to_categorical(y_test,10)

    ## Use the data into the Architecture 
    model=Sequential()
    model.add(Input((28,28)))
    model.add(Flatten())
    model.add(Dense(128,activation="relu"))
    model.add(Dense(64,activation="relu"))
    model.add(Dense(10,activation="softmax"))

    ## Compile and Train the Model
    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=10, batch_size=32)

    Epoch 1/10
    WARNING:tensorflow:From C:\Users\hp\anaconda3\Lib\site-packages\keras\src\utils\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.

    WARNING:tensorflow:From C:\Users\hp\anaconda3\Lib\site-packages\keras\src\engine\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.

    1875/1875 [==============================] - 6s 3ms/step - loss: 0.2428 - accuracy: 0.9287
    Epoch 2/10
    1875/1875 [==============================] - 5s 3ms/step - loss: 0.1002 - accuracy: 0.9700
    Epoch 3/10
    1875/1875 [==============================] - 5s 3ms/step - loss: 0.0718 - accuracy: 0.9768
    Epoch 4/10
    1875/1875 [==============================] - 5s 3ms/step - loss: 0.0528 - accuracy: 0.9835
    Epoch 5/10
    1875/1875 [==============================] - 5s 3ms/step - loss: 0.0413 - accuracy: 0.9869
    Epoch 6/10
    1875/1875 [==============================] - 5s 3ms/step - loss: 0.0347 - accuracy: 0.9886
    Epoch 7/10
    1875/1875 [==============================] - 5s 3ms/step - loss: 0.0293 - accuracy: 0.9904
    Epoch 8/10
    1875/1875 [==============================] - 5s 3ms/step - loss: 0.0239 - accuracy: 0.9918
    Epoch 9/10
    1875/1875 [==============================] - 6s 3ms/step - loss: 0.0208 - accuracy: 0.9933
    Epoch 10/10
    1875/1875 [==============================] - 5s 3ms/step - loss: 0.0195 - accuracy: 0.9934

    <keras.src.callbacks.History at 0x213d8cc5090>

    ## Predict the output 
    y_pred=np.argmax(model.predict(X_test),axis=1) ## Using Argmax to get the maximum output from Probability
    y_test_labels=np.argmax(y_test,axis=1)
    print("Classification Report:")
    print(classification_report(y_test_labels,y_pred))
    print("Confusion Matrix:")
    confusion_matrix(y_test_labels,y_pred)

    313/313 [==============================] - 1s 2ms/step
    Classification Report:
                  precision    recall  f1-score   support

               0       0.98      0.99      0.98       980
               1       0.99      0.99      0.99      1135
               2       0.99      0.96      0.98      1032
               3       0.93      0.99      0.96      1010
               4       0.99      0.99      0.99       982
               5       0.98      0.96      0.97       892
               6       0.99      0.98      0.98       958
               7       0.99      0.98      0.98      1028
               8       0.99      0.96      0.97       974
               9       0.96      0.98      0.97      1009

        accuracy                           0.98     10000
       macro avg       0.98      0.98      0.98     10000
    weighted avg       0.98      0.98      0.98     10000

    Confusion Matrix:

    array([[ 971,    0,    0,    3,    0,    0,    4,    0,    1,    1],
           [   0, 1124,    1,    3,    0,    1,    2,    1,    2,    1],
           [   6,    2,  995,   17,    1,    0,    1,    6,    3,    1],
           [   0,    0,    0, 1001,    0,    2,    0,    0,    2,    5],
           [   0,    0,    2,    1,  968,    1,    2,    0,    0,    8],
           [   2,    0,    0,   19,    0,  855,    4,    1,    3,    8],
           [   6,    2,    1,    1,    5,    5,  936,    0,    2,    0],
           [   1,    3,    5,    4,    1,    0,    0, 1003,    0,   11],
           [   3,    0,    1,   20,    2,    6,    1,    4,  932,    5],
           [   3,    2,    0,    8,    4,    1,    0,    1,    0,  990]],
          dtype=int64)

Transfer Learning

    import pandas as pd
    import tensorflow as tf 
    from tensorflow.keras.applications import VGG16
    import zipfile
    from tensorflow.keras.preprocessing.image import ImageDataGenerator
    from tensorflow.keras.layers import Input

    url="https://storage.googleapi.com/mledu-datasets/cats_and_dogs_filtered.zip"
    filename=tf.keras.utils.get_file("cats_and_dogs_filtered.zip",url,extract=True)
    with zipfile.ZipFile(filename,"r") as file:
        file.extractall()

    ## Train and Validation Directory
    train_dir="D:\\Darshit\\Gen AI\\cats_and_dogs_filtered\\train"
    validation_dir="D:\\Darshit\\Gen AI\\cats_and_dogs_filtered\\validation"

    ## Generate Training and validation data 
    train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=20,width_shift_range=0.2,zoom_range=0.2,shear_range=0.2,horizontal_flip=True)
    validation_datagen=ImageDataGenerator(rescale=1/255)

    train_generator=train_datagen.flow_from_directory(train_dir,target_size=(150,150),batch_size=20,class_mode="binary")
    validation_generator=validation_datagen.flow_from_directory(validation_dir,target_size=(150,150),batch_size=20,class_mode="binary")

    Found 2000 images belonging to 2 classes.
    Found 1000 images belonging to 2 classes.

    ## Load the Pre Trained Model 
    conv_base=VGG16(classes=(150,150,3),include_top=False,weights="imagenet")
    conv_base.trainable=False

    ## Define the Architecture 
    model=Sequential()
    model.add(Input((150,150,3)))
    model.add(conv_base)
    model.add(Flatten())
    model.add(Dense(256,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1,activation="Softmax"))

    with tf.device(":/GPU:0"):
        model.compile(optimizer=Adam(),loss="categorical_crossentropy",metrics=["accuracy"])
        model.fit(train_generator,epochs=10,validation_steps=50,validation_data=validation_generator)

    Epoch 1/10

    C:\Users\hp\anaconda3\Lib\site-packages\tensorflow\python\util\dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.
      return dispatch_target(*args, **kwargs)

    100/100 [==============================] - 154s 2s/step - loss: 0.0000e+00 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.5000
    Epoch 2/10
    100/100 [==============================] - 147s 1s/step - loss: 0.0000e+00 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.5000
    Epoch 3/10
     15/100 [===>..........................] - ETA: 1:24 - loss: 0.0000e+00 - accuracy: 0.4533

    ---------------------------------------------------------------------------
    KeyboardInterrupt                         Traceback (most recent call last)
    Cell In[40], line 3
          1 with tf.device(":/GPU:0"):
          2     model.compile(optimizer=Adam(),loss="categorical_crossentropy",metrics=["accuracy"])
    ----> 3     model.fit(train_generator,epochs=10,validation_steps=50,validation_data=validation_generator)

    File ~\anaconda3\Lib\site-packages\keras\src\utils\traceback_utils.py:65, in filter_traceback.<locals>.error_handler(*args, **kwargs)
         63 filtered_tb = None
         64 try:
    ---> 65     return fn(*args, **kwargs)
         66 except Exception as e:
         67     filtered_tb = _process_traceback_frames(e.__traceback__)

    File ~\anaconda3\Lib\site-packages\keras\src\engine\training.py:1807, in Model.fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
       1799 with tf.profiler.experimental.Trace(
       1800     "train",
       1801     epoch_num=epoch,
       (...)
       1804     _r=1,
       1805 ):
       1806     callbacks.on_train_batch_begin(step)
    -> 1807     tmp_logs = self.train_function(iterator)
       1808     if data_handler.should_sync:
       1809         context.async_wait()

    File ~\anaconda3\Lib\site-packages\tensorflow\python\util\traceback_utils.py:150, in filter_traceback.<locals>.error_handler(*args, **kwargs)
        148 filtered_tb = None
        149 try:
    --> 150   return fn(*args, **kwargs)
        151 except Exception as e:
        152   filtered_tb = _process_traceback_frames(e.__traceback__)

    File ~\anaconda3\Lib\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py:832, in Function.__call__(self, *args, **kwds)
        829 compiler = "xla" if self._jit_compile else "nonXla"
        831 with OptionalXlaContext(self._jit_compile):
    --> 832   result = self._call(*args, **kwds)
        834 new_tracing_count = self.experimental_get_tracing_count()
        835 without_tracing = (tracing_count == new_tracing_count)

    File ~\anaconda3\Lib\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py:868, in Function._call(self, *args, **kwds)
        865   self._lock.release()
        866   # In this case we have created variables on the first call, so we run the
        867   # defunned version which is guaranteed to never create variables.
    --> 868   return tracing_compilation.call_function(
        869       args, kwds, self._no_variable_creation_config
        870   )
        871 elif self._variable_creation_config is not None:
        872   # Release the lock early so that multiple threads can perform the call
        873   # in parallel.
        874   self._lock.release()

    File ~\anaconda3\Lib\site-packages\tensorflow\python\eager\polymorphic_function\tracing_compilation.py:139, in call_function(args, kwargs, tracing_options)
        137 bound_args = function.function_type.bind(*args, **kwargs)
        138 flat_inputs = function.function_type.unpack_inputs(bound_args)
    --> 139 return function._call_flat(  # pylint: disable=protected-access
        140     flat_inputs, captured_inputs=function.captured_inputs
        141 )

    File ~\anaconda3\Lib\site-packages\tensorflow\python\eager\polymorphic_function\concrete_function.py:1323, in ConcreteFunction._call_flat(self, tensor_inputs, captured_inputs)
       1319 possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)
       1320 if (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE
       1321     and executing_eagerly):
       1322   # No tape is watching; skip to running the function.
    -> 1323   return self._inference_function.call_preflattened(args)
       1324 forward_backward = self._select_forward_and_backward_functions(
       1325     args,
       1326     possible_gradient_type,
       1327     executing_eagerly)
       1328 forward_function, args_with_tangents = forward_backward.forward()

    File ~\anaconda3\Lib\site-packages\tensorflow\python\eager\polymorphic_function\atomic_function.py:216, in AtomicFunction.call_preflattened(self, args)
        214 def call_preflattened(self, args: Sequence[core.Tensor]) -> Any:
        215   """Calls with flattened tensor inputs and returns the structured output."""
    --> 216   flat_outputs = self.call_flat(*args)
        217   return self.function_type.pack_output(flat_outputs)

    File ~\anaconda3\Lib\site-packages\tensorflow\python\eager\polymorphic_function\atomic_function.py:251, in AtomicFunction.call_flat(self, *args)
        249 with record.stop_recording():
        250   if self._bound_context.executing_eagerly():
    --> 251     outputs = self._bound_context.call_function(
        252         self.name,
        253         list(args),
        254         len(self.function_type.flat_outputs),
        255     )
        256   else:
        257     outputs = make_call_op_in_graph(
        258         self,
        259         list(args),
        260         self._bound_context.function_call_options.as_attrs(),
        261     )

    File ~\anaconda3\Lib\site-packages\tensorflow\python\eager\context.py:1486, in Context.call_function(self, name, tensor_inputs, num_outputs)
       1484 cancellation_context = cancellation.context()
       1485 if cancellation_context is None:
    -> 1486   outputs = execute.execute(
       1487       name.decode("utf-8"),
       1488       num_outputs=num_outputs,
       1489       inputs=tensor_inputs,
       1490       attrs=attrs,
       1491       ctx=self,
       1492   )
       1493 else:
       1494   outputs = execute.execute_with_cancellation(
       1495       name.decode("utf-8"),
       1496       num_outputs=num_outputs,
       (...)
       1500       cancellation_manager=cancellation_context,
       1501   )

    File ~\anaconda3\Lib\site-packages\tensorflow\python\eager\execute.py:53, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
         51 try:
         52   ctx.ensure_initialized()
    ---> 53   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
         54                                       inputs, attrs, num_outputs)
         55 except core._NotOkStatusException as e:
         56   if name is not None:

    KeyboardInterrupt: 

    x,y_true=next(validation_generator)
    y_pred=np.argmax(model.predict(X_test),axis=1)
    class_names=["dog","cat"]
    for i in range(len(x)):
        plt.imshow(x[i])
        plt.title(f"Predicted Class {class_names[int(round(y_pred[i][0]))]}, True Class:{class_names[int(round(y_pred[i]))]}")
        plt.show()

CNN in Image Classification

    import pandas as pd 
    import numpy as np 
    import matplotlib.pyplot as plt
    import tensorflow as tf
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.utils import to_categorical
    from tensorflow.keras.layers import Input,Dense,Flatten,Dropout,Conv2D,MaxPooling2D
    from tensorflow.keras.optimizers import Adam
    from sklearn.metrics import classification_report,confusion_matrix
    import tensorflow.keras.datasets as td

    ## Generate the Data 
    (X_train,y_train),(X_test,y_test)=td.mnist.load_data()

    ## Preprocess the data
    X_train=X_train.astype("float32")/255.0
    X_test=X_test.astype("float32")/255.0
    X_train=np.expand_dims(X_train,-1)
    X_test=np.expand_dims(X_test,-1)

    ## Form the Architecture 
    with tf.device(":/GPU:0"):
        model=Sequential()
        model.add(Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))
        model.add(MaxPooling2D((2,2)))
        model.add(Conv2D(64,(3,3),activation="relu"))
        model.add(MaxPooling2D((2,2)))
        model.add(Flatten())
        model.add(Dense(64,activation="relu"))
        model.add(Dense(10,activation='softmax'))

    ## Compile and fit the model 
    with tf.device("/GPU:0"):
        model.compile(loss="sparse_categorical_crossentropy",optimizer=Adam(),metrics=["accuracy"])
        model.fit(X_train,y_train,epochs=10,steps_per_epoch=10,validation_data=(X_test,y_test))

    Epoch 1/10
    10/10 [==============================] - 9s 816ms/step - loss: 2.0685 - accuracy: 0.4426 - val_loss: 1.6109 - val_accuracy: 0.7587
    Epoch 2/10
    10/10 [==============================] - 7s 744ms/step - loss: 1.1216 - accuracy: 0.7884 - val_loss: 0.6223 - val_accuracy: 0.8395
    Epoch 3/10
    10/10 [==============================] - 8s 772ms/step - loss: 0.4979 - accuracy: 0.8588 - val_loss: 0.3708 - val_accuracy: 0.8965
    Epoch 4/10
    10/10 [==============================] - 7s 759ms/step - loss: 0.3374 - accuracy: 0.9034 - val_loss: 0.2689 - val_accuracy: 0.9228
    Epoch 5/10
    10/10 [==============================] - 7s 739ms/step - loss: 0.2548 - accuracy: 0.9258 - val_loss: 0.2040 - val_accuracy: 0.9408
    Epoch 6/10
    10/10 [==============================] - 7s 754ms/step - loss: 0.1989 - accuracy: 0.9424 - val_loss: 0.1617 - val_accuracy: 0.9530
    Epoch 7/10
    10/10 [==============================] - 7s 754ms/step - loss: 0.1635 - accuracy: 0.9522 - val_loss: 0.1361 - val_accuracy: 0.9619
    Epoch 8/10
    10/10 [==============================] - 7s 754ms/step - loss: 0.1387 - accuracy: 0.9597 - val_loss: 0.1165 - val_accuracy: 0.9670
    Epoch 9/10
    10/10 [==============================] - 7s 746ms/step - loss: 0.1217 - accuracy: 0.9648 - val_loss: 0.1022 - val_accuracy: 0.9703
    Epoch 10/10
    10/10 [==============================] - 7s 751ms/step - loss: 0.1095 - accuracy: 0.9678 - val_loss: 0.0935 - val_accuracy: 0.9717

    test_loss,test_accuracy=model.evaluate(X_test,y_test)
    print("Test Accuracy",test_accuracy)

    313/313 [==============================] - 1s 4ms/step - loss: 0.0935 - accuracy: 0.9717
    Test Accuracy 0.9717000126838684

    ## For prediction and testing 
    sample_img=X_test[0]
    sample_label=y_test[0]
    sample_img=np.expand_dims(sample_img,0)
    pred=model.predict(sample_img)
    pred_loabel=np.argmax(pred)
    print("Sample Image True Label",sample_label)
    print("Sample Image Predicted Label",pred_loabel)

    1/1 [==============================] - 0s 30ms/step
    Sample Image True Label 7
    Sample Image Predicted Label 7

    plt.imshow(sample_img.squeeze(),cmap="gray")
    plt.show()

[]

RNN
